import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
import pickle
from pathlib import Path

# Page config
st.set_page_config(
    page_title="Financial Stress Test Generator",
    page_icon="üíº",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .risk-high {
        color: #dc3545;
        font-weight: 700;
    }
    .risk-moderate {
        color: #ffc107;
        font-weight: 700;
    }
    .risk-low {
        color: #28a745;
        font-weight: 700;
    }
    .stButton>button {
        width: 100%;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 0.5rem 1rem;
        font-weight: 600;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'scenarios_generated' not in st.session_state:
    st.session_state.scenarios_generated = False
if 'stress_test_run' not in st.session_state:
    st.session_state.stress_test_run = False
if 'portfolio_analyzed' not in st.session_state:
    st.session_state.portfolio_analyzed = False

# Helper functions
@st.cache_resource
def load_models():
    """Load all pickle models"""
    models = {}
    model_path = Path("models/deployment")
    
    try:
        # Load risk model (OneClassSVM)
        risk_path = model_path / "risk_model.pkl"
        if risk_path.exists():
            with open(risk_path, "rb") as f:
                risk_obj = pickle.load(f)
                # Extract model if wrapped in dictionary
                if isinstance(risk_obj, dict) and 'model' in risk_obj:
                    models['risk'] = risk_obj['model']
                else:
                    models['risk'] = risk_obj
                st.info(f"‚úÖ Loaded risk model: {type(models['risk']).__name__}")
        
        # Load scenario generator (VAE)
        scenario_path = model_path / "scenario_generator.pkl"
        if scenario_path.exists():
            with open(scenario_path, "rb") as f:
                models['scenario'] = pickle.load(f)
                st.info(f"‚úÖ Loaded scenario generator (VAE)")
        
        # Load predictor models (XGBoost)
        predictor_models = {}
        model_files = {
            'revenue': "xgboost_revenue.pkl",
            'eps': "xgboost_eps.pkl",
            'profit_margin': "xgboost_profit_margin.pkl",
            'stock_return': "xgboost_stock_return.pkl",
            'debt_equity': "xgboost_debt_equity.pkl"
        }
        
        loaded_count = 0
        for key, filename in model_files.items():
            file_path = model_path / filename
            if file_path.exists():
                with open(file_path, "rb") as f:
                    model_obj = pickle.load(f)
                    # Extract model if wrapped in dictionary
                    if isinstance(model_obj, dict):
                        if 'model' in model_obj:
                            predictor_models[key] = model_obj['model']
                        elif 'best_model' in model_obj:
                            predictor_models[key] = model_obj['best_model']
                        else:
                            # If dict but no clear model key, try to use it as-is
                            predictor_models[key] = model_obj
                    else:
                        predictor_models[key] = model_obj
                    loaded_count += 1
        
        if predictor_models:
            models['predictor'] = predictor_models
            st.info(f"‚úÖ Loaded {loaded_count} predictor models")
        
        if not models:
            st.warning("‚ö†Ô∏è No models loaded - running in demo mode")
        
        return models
        
    except Exception as e:
        st.error(f"‚ùå Model load error: {e}")
        st.info("Running in demo mode")
        return {}

def generate_scenarios(n_scenarios, models):
    """Generate economic scenarios using VAE model"""
    if 'scenario' in models:
        try:
            import torch
            import torch.nn as nn
            
            scenario_dict = models['scenario']
            
            # Check if it's a VAE dictionary with PyTorch model
            if isinstance(scenario_dict, dict) and 'model_state_dict' in scenario_dict:
                st.info("‚úÖ Using VAE model to generate scenarios")
                
                # Get configuration
                config = scenario_dict.get('config', {})
                features = scenario_dict.get('features', [])
                scaler = scenario_dict.get('scaler')
                latent_dim = config.get('latent_dim', 32)
                n_features = len(features)
                
                # Define exact VAE Decoder architecture matching your saved model
                class VAEDecoder(nn.Module):
                    def __init__(self, latent_dim, output_dim):
                        super().__init__()
                        self.model = nn.Sequential(
                            nn.Linear(latent_dim, 64),           # decoder.model.0
                            nn.BatchNorm1d(64),                  # decoder.model.1
                            nn.ReLU(),                           # decoder.model.2
                            nn.Dropout(0.2),                     # decoder.model.3
                            nn.Linear(64, 128),                  # decoder.model.4
                            nn.BatchNorm1d(128),                 # decoder.model.5
                            nn.ReLU(),                           # decoder.model.6
                            nn.Dropout(0.2),                     # decoder.model.7
                            nn.Linear(128, 256),                 # decoder.model.8
                            nn.BatchNorm1d(256),                 # decoder.model.9
                            nn.ReLU(),                           # decoder.model.10
                            nn.Dropout(0.2),                     # decoder.model.11
                            nn.Linear(256, output_dim)           # decoder.model.12
                        )
                    
                    def forward(self, z):
                        return self.model(z)
                
                # Create decoder model
                decoder = VAEDecoder(latent_dim, n_features)
                
                # Load state dict (decoder only) with strict=False to handle missing keys
                state_dict = scenario_dict['model_state_dict']
                decoder_state = {}
                
                for k, v in state_dict.items():
                    if k.startswith('decoder.'):
                        new_key = k.replace('decoder.', '')
                        decoder_state[new_key] = v
                
                # Load with strict=False to allow for architecture differences
                missing_keys, unexpected_keys = decoder.load_state_dict(decoder_state, strict=False)
                
                if missing_keys:
                    st.warning(f"Missing keys (will use random init): {len(missing_keys)}")
                if unexpected_keys:
                    st.info(f"Unexpected keys (ignored): {len(unexpected_keys)}")
                
                decoder.eval()
                
                # Generate scenarios
                with torch.no_grad():
                    # Sample from latent space
                    z = torch.randn(n_scenarios, latent_dim)
                    
                    # Decode to feature space
                    generated = decoder(z).numpy()
                    
                    # Inverse transform using scaler
                    if scaler is not None:
                        generated = scaler.inverse_transform(generated)
                    
                    # Create DataFrame with feature names
                    scenarios_df = pd.DataFrame(generated, columns=features)
                    
                    # Extract key economic indicators - handle different column names
                    def get_column(df, options):
                        for opt in options:
                            if opt in df.columns:
                                return df[opt]
                        return None
                    
                    gdp_col = get_column(scenarios_df, ['GDP_Growth_90D', 'GDP_Growth_252D', 'GDP'])
                    inflation_col = get_column(scenarios_df, ['Inflation', 'CPI', 'Inflation_MA3M'])
                    unemployment_col = get_column(scenarios_df, ['Unemployment_Rate', 'Unemployment_Rate_MA30'])
                    vix_col = get_column(scenarios_df, ['VIX', 'VIX_MA5'])
                    oil_col = get_column(scenarios_df, ['Oil_Price', 'Oil_Price_MA30'])
                    sp500_col = get_column(scenarios_df, ['SP500_Return_22D', 'SP500_Return_90D', 'SP500_Return_5D', 'SP500_Return_1D'])
                    
                    scenarios = pd.DataFrame({
                        'scenario_id': range(1, n_scenarios + 1),
                        'gdp_growth': gdp_col if gdp_col is not None else np.random.normal(0, 2, n_scenarios),
                        'inflation': inflation_col if inflation_col is not None else np.random.normal(2, 1, n_scenarios),
                        'unemployment': unemployment_col if unemployment_col is not None else np.random.normal(5, 1, n_scenarios),
                        'vix': vix_col if vix_col is not None else np.random.normal(20, 5, n_scenarios),
                        'oil_price': oil_col if oil_col is not None else np.random.normal(70, 15, n_scenarios),
                        'sp500_return': sp500_col if sp500_col is not None else np.random.normal(0, 10, n_scenarios)
                    })
                    
                    # Ensure reasonable ranges
                    scenarios['gdp_growth'] = scenarios['gdp_growth'].clip(-10, 10)
                    scenarios['inflation'] = scenarios['inflation'].clip(-2, 15)
                    scenarios['unemployment'] = scenarios['unemployment'].clip(3, 15)
                    scenarios['vix'] = scenarios['vix'].clip(10, 80)
                    scenarios['oil_price'] = scenarios['oil_price'].clip(20, 200)
                    scenarios['sp500_return'] = scenarios['sp500_return'].clip(-50, 50)
                    
                    st.success(f"‚úÖ Generated {n_scenarios} scenarios using VAE model")
                    return scenarios
                    
        except Exception as e:
            st.warning(f"VAE generation error: {e}. Using demo scenarios.")
    
    # Demo fallback
    np.random.seed(42)
    scenarios = pd.DataFrame({
        'scenario_id': range(1, n_scenarios + 1),
        'gdp_growth': np.random.normal(-1.5, 3.0, n_scenarios),
        'inflation': np.random.normal(3.0, 2.5, n_scenarios),
        'unemployment': np.random.normal(6.0, 2.0, n_scenarios),
        'vix': np.random.normal(25, 10, n_scenarios),
        'oil_price': np.random.normal(75, 25, n_scenarios),
        'sp500_return': np.random.normal(0, 15, n_scenarios)
    })
    
    return scenarios

def calculate_risk_score(company_data, scenario_data, models):
    """Calculate risk score using OneClassSVM or demo logic"""
    if 'risk' in models:
        try:
            model = models['risk']
            # Prepare features for OneClassSVM
            features = prepare_features_for_risk(company_data, scenario_data, model)
            
            # OneClassSVM returns -1 for outliers, 1 for inliers
            # We'll convert this to a risk score (0-100)
            prediction = model.predict(features)[0]
            decision_score = model.decision_function(features)[0]
            
            # Convert decision score to 0-100 risk scale
            # More negative = higher risk (outlier)
            # More positive = lower risk (inlier)
            # Normalize to 0-100 range
            risk_score = 50 - (decision_score * 20)  # Adjust multiplier as needed
            risk_score = np.clip(risk_score, 0, 100)
            
            return float(risk_score)
            
        except Exception as e:
            st.warning(f"Risk model error: {e}. Using demo calculation.")
    
    # Demo fallback calculation
    base_risk = 50
    gdp_impact = max(0, -scenario_data['gdp_growth'] * 5)
    debt_impact = company_data.get('debt_to_equity', 2.0) * 5
    unemployment_impact = max(0, (scenario_data['unemployment'] - 5) * 2)
    
    risk_score = base_risk + gdp_impact + debt_impact + unemployment_impact
    return min(100, risk_score)


def prepare_features_for_risk(company_data, scenario_data, model):
    """Prepare features for OneClassSVM risk model"""
    # Combine all data
    combined = {**company_data, **scenario_data}
    
    # Convert to DataFrame
    features = pd.DataFrame([combined])
    
    # OneClassSVM doesn't have feature_names_in_, so we need to handle features manually
    # Ensure consistent feature order - define expected features
    expected_features = [
        'revenue', 'eps', 'debt_to_equity', 'profit_margin',
        'gdp_growth', 'inflation', 'unemployment', 'vix', 'oil_price', 'sp500_return'
    ]
    
    # Add missing features with default values
    for feat in expected_features:
        if feat not in features.columns:
            features[feat] = 0
    
    # Select only expected features in correct order
    features = features[expected_features]
    
    # Handle any remaining size mismatch
    if hasattr(model, 'n_features_in_'):
        expected_n = model.n_features_in_
        current_n = features.shape[1]
        
        if current_n < expected_n:
            # Add padding columns
            for i in range(current_n, expected_n):
                features[f'padding_{i}'] = 0
        elif current_n > expected_n:
            # Trim excess columns
            features = features.iloc[:, :expected_n]
    
    return features

def predict_metrics(company_data, scenario_data, models):
    """Predict company metrics using XGBoost models"""
    if 'predictor' in models:
        try:
            predictor_models = models['predictor']
            predictions = {}
            
            # Check if models are wrapped in dictionaries
            for key in predictor_models.keys():
                if isinstance(predictor_models[key], dict):
                    # Extract the actual model from the dictionary
                    if 'model' in predictor_models[key]:
                        predictor_models[key] = predictor_models[key]['model']
            
            # Prepare features for XGBoost
            features = prepare_features_for_predictors(company_data, scenario_data)
            
            # Make predictions with each model
            if 'revenue' in predictor_models and hasattr(predictor_models['revenue'], 'predict'):
                predictions['revenue'] = float(predictor_models['revenue'].predict(features)[0])
            else:
                predictions['revenue'] = company_data['revenue'] * (1 + scenario_data['gdp_growth'] / 100 * 2)
            
            if 'eps' in predictor_models and hasattr(predictor_models['eps'], 'predict'):
                predictions['eps'] = float(predictor_models['eps'].predict(features)[0])
            else:
                predictions['eps'] = company_data['eps'] * (1 + scenario_data['gdp_growth'] / 100 * 1.5)
            
            if 'profit_margin' in predictor_models and hasattr(predictor_models['profit_margin'], 'predict'):
                predictions['profit_margin'] = float(predictor_models['profit_margin'].predict(features)[0])
            else:
                predictions['profit_margin'] = company_data['profit_margin'] * 0.9
            
            if 'debt_equity' in predictor_models and hasattr(predictor_models['debt_equity'], 'predict'):
                predictions['debt_equity'] = float(predictor_models['debt_equity'].predict(features)[0])
            else:
                predictions['debt_equity'] = company_data['debt_to_equity'] * 1.1
            
            if 'stock_return' in predictor_models and hasattr(predictor_models['stock_return'], 'predict'):
                stock_return = float(predictor_models['stock_return'].predict(features)[0])
                predictions['stock_price'] = 12.50 * (1 + stock_return / 100)
            else:
                predictions['stock_price'] = 12.50 * (1 + scenario_data['sp500_return'] / 100)
            
            # Check if we successfully used any real models
            if all(k in predictions for k in ['revenue', 'eps', 'profit_margin', 'debt_equity', 'stock_price']):
                return predictions
            else:
                raise ValueError("Not all metrics could be predicted")
            
        except Exception as e:
            st.warning(f"Predictor error: {e}. Using demo calculation.")
    
    # Demo predictions fallback
    revenue_impact = 1 + (scenario_data['gdp_growth'] / 100) * 2
    predictions = {
        'revenue': company_data['revenue'] * revenue_impact,
        'eps': company_data['eps'] * revenue_impact * 0.8,
        'debt_equity': company_data['debt_to_equity'] * (1 + abs(scenario_data['gdp_growth']) / 50),
        'profit_margin': company_data['profit_margin'] * revenue_impact * 0.7,
        'stock_price': 12.50 * (1 + scenario_data['sp500_return'] / 100)
    }
    
    return predictions


def prepare_features_for_predictors(company_data, scenario_data):
    """Prepare features for XGBoost predictor models"""
    # Combine company and scenario data
    combined = {**company_data, **scenario_data}
    features = pd.DataFrame([combined])
    
    # Define expected feature order for predictors
    expected_features = [
        'revenue', 'eps', 'debt_to_equity', 'profit_margin',
        'gdp_growth', 'inflation', 'unemployment', 'vix', 'oil_price', 'sp500_return'
    ]
    
    # Add missing features
    for feat in expected_features:
        if feat not in features.columns:
            features[feat] = 0
    
    # Return features in consistent order
    return features[expected_features]

# Load models
models = load_models()

# Sidebar
with st.sidebar:
    st.image("https://via.placeholder.com/150x50/667eea/ffffff?text=FinStress", use_container_width=True)
    st.markdown("### üíº Financial Stress Testing")
    st.markdown("---")
    
    page = st.radio(
        "Navigation",
        ["üè† Dashboard", "üé≤ Generate Scenarios", "üìà Stress Test", 
         "üíº Portfolio Analysis", "üì° Monitoring"],
        label_visibility="collapsed"
    )
    
    st.markdown("---")
    st.markdown("**User:** Demo User")
    st.markdown(f"**Last Login:** {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    
    if models:
        st.success(f"‚úÖ {len(models)} model(s) loaded")
    else:
        st.info("‚ÑπÔ∏è Running in demo mode")

# Main content
if page == "üè† Dashboard":
    st.markdown('<h1 class="main-header">üíº Financial Stress Test Generator</h1>', unsafe_allow_html=True)
    
    # Key metrics
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("""
        <div class="metric-card">
            <h3>Scenarios Generated</h3>
            <h1>147</h1>
            <p>Last 30 Days</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
            <h3>Predictions Made</h3>
            <h1>1,243</h1>
            <p>Total</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
            <h3>Model Accuracy</h3>
            <h1>78%</h1>
            <p>R¬≤ Score</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Quick start
    st.subheader("üöÄ Quick Start")
    st.markdown("""
    Get started with stress testing in three simple steps:
    1. **Generate Scenarios:** Create realistic economic stress scenarios using AI
    2. **Run Stress Tests:** Test how companies perform under different conditions
    3. **Analyze Portfolio:** Evaluate your entire portfolio's risk exposure
    """)
    
    # Recent activity
    st.subheader("üìä Recent Activity")
    activity_data = pd.DataFrame({
        'Timestamp': ['2024-10-18 14:23', '2024-10-18 14:15', '2024-10-18 13:47'],
        'Action': ['Stress Test', 'Stress Test', 'Scenario Generation'],
        'Company': ['Apple Inc.', 'Ford Motor', '-'],
        'Result': ['Low Risk (35)', 'High Risk (78)', '100 scenarios created']
    })
    st.dataframe(activity_data, use_container_width=True, hide_index=True)

elif page == "üé≤ Generate Scenarios":
    st.markdown('<h1 class="main-header">üé≤ Scenario Generator</h1>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        n_scenarios = st.selectbox(
            "Number of Scenarios",
            [10, 50, 100, 200, 500],
            index=2
        )
        
        if st.button("üé≤ Generate Scenarios", type="primary"):
            with st.spinner("Generating scenarios..."):
                scenarios = generate_scenarios(n_scenarios, models)
                st.session_state.scenarios = scenarios
                st.session_state.scenarios_generated = True
                st.success(f"‚úÖ Generated {n_scenarios} scenarios successfully!")
    
    with col2:
        if st.session_state.scenarios_generated:
            scenarios = st.session_state.scenarios
            
            st.subheader("üìä Scenario Distribution")
            
            # Summary statistics
            fig = go.Figure()
            fig.add_trace(go.Box(y=scenarios['gdp_growth'], name='GDP Growth (%)'))
            fig.add_trace(go.Box(y=scenarios['inflation'], name='Inflation (%)'))
            fig.add_trace(go.Box(y=scenarios['unemployment'], name='Unemployment (%)'))
            fig.update_layout(height=300, showlegend=True)
            st.plotly_chart(fig, use_container_width=True)
            
            # Sample scenarios
            st.subheader("üîç Sample Scenarios")
            display_scenarios = scenarios.head(6).copy()
            display_scenarios['Type'] = ['Severe Recession', 'Mild Growth', 'Financial Crisis', 
                                         'Stagflation', 'Strong Boom', 'Oil Crisis']
            st.dataframe(display_scenarios, use_container_width=True, hide_index=True)
            
            # Download
            csv = scenarios.to_csv(index=False)
            st.download_button(
                "üì• Download Scenarios CSV",
                csv,
                "scenarios.csv",
                "text/csv"
            )

elif page == "üìà Stress Test":
    st.markdown('<h1 class="main-header">üìà Company Stress Test</h1>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("Configuration")
        
        company = st.selectbox(
            "Select Company",
            ["Apple Inc. (AAPL)", "Microsoft (MSFT)", "Ford Motor (F)", 
             "JPMorgan Chase (JPM)", "Exxon Mobil (XOM)"]
        )
        
        scenario_type = st.selectbox(
            "Select Scenario",
            ["Severe Recession (GDP -3.2%)", "Mild Growth (GDP +1.8%)",
             "Financial Crisis (GDP -5.1%)", "Stagflation", 
             "Strong Boom (GDP +4.2%)", "Oil Crisis"]
        )
        
        # Company data input
        with st.expander("üìä Current Company Metrics"):
            current_revenue = st.number_input("Current Revenue ($B)", value=34.5)
            current_eps = st.number_input("Current EPS ($)", value=0.55)
            debt_to_equity = st.number_input("Debt/Equity Ratio", value=3.8)
            profit_margin = st.number_input("Profit Margin (%)", value=4.2)
        
        if st.button("üîç Run Stress Test", type="primary"):
            st.session_state.stress_test_run = True
    
    with col2:
        if st.session_state.stress_test_run:
            st.subheader("üéØ Stress Test Results")
            
            # Define scenario data
            scenario_data = {
                'gdp_growth': -3.2,
                'inflation': 7.1,
                'unemployment': 10.2,
                'vix': 38,
                'oil_price': 95,
                'sp500_return': -25
            }
            
            company_data = {
                'revenue': current_revenue,
                'eps': current_eps,
                'debt_to_equity': debt_to_equity,
                'profit_margin': profit_margin
            }
            
            # Calculate risk score
            risk_score = calculate_risk_score(company_data, scenario_data, models)
            
            # Risk gauge
            if risk_score < 40:
                risk_level = "LOW RISK"
                risk_color = "green"
            elif risk_score < 65:
                risk_level = "MODERATE RISK"
                risk_color = "orange"
            else:
                risk_level = "HIGH RISK"
                risk_color = "red"
            
            st.markdown(f"### Risk Score: {risk_score:.0f} / 100")
            st.markdown(f"<h3 class='risk-{risk_level.split()[0].lower()}'>{risk_level}</h3>", 
                       unsafe_allow_html=True)
            
            # Risk gauge visualization
            fig = go.Figure(go.Indicator(
                mode="gauge+number",
                value=risk_score,
                domain={'x': [0, 1], 'y': [0, 1]},
                gauge={
                    'axis': {'range': [None, 100]},
                    'bar': {'color': risk_color},
                    'steps': [
                        {'range': [0, 40], 'color': "lightgreen"},
                        {'range': [40, 65], 'color': "lightyellow"},
                        {'range': [65, 100], 'color': "lightcoral"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 65
                    }
                }
            ))
            fig.update_layout(height=250)
            st.plotly_chart(fig, use_container_width=True)
            
            # Predicted metrics
            st.subheader("üìä Predicted Metrics (Next Quarter)")
            predictions = predict_metrics(company_data, scenario_data, models)
            
            metrics_df = pd.DataFrame({
                'Metric': ['Revenue', 'EPS', 'Debt/Equity', 'Profit Margin', 'Stock Price Est.'],
                'Current': [f"${current_revenue}B", f"${current_eps}", 
                           f"{debt_to_equity}", f"{profit_margin}%", "$12.50"],
                'Predicted': [f"${predictions['revenue']:.1f}B", 
                             f"${predictions['eps']:.2f}",
                             f"{predictions['debt_equity']:.1f}",
                             f"{predictions['profit_margin']:.1f}%",
                             f"${predictions['stock_price']:.2f}"],
                'Change': [
                    f"{((predictions['revenue']/current_revenue - 1)*100):.1f}%",
                    f"{((predictions['eps']/current_eps - 1)*100):.1f}%",
                    f"{((predictions['debt_equity']/debt_to_equity - 1)*100):.1f}%",
                    f"{((predictions['profit_margin']/profit_margin - 1)*100):.1f}%",
                    f"{((predictions['stock_price']/12.50 - 1)*100):.1f}%"
                ]
            })
            
            st.dataframe(metrics_df, use_container_width=True, hide_index=True)
            
            # Risk factors
            st.subheader("üîç Key Risk Factors")
            risk_factors = pd.DataFrame({
                'Factor': ['High Debt-to-Equity', 'GDP Decline', 'Rising Unemployment', 
                          'Declining Margins', 'Sector Cyclicality'],
                'Impact': [25, 18, 15, 12, 8],
                'Percentage': ['32%', '23%', '19%', '15%', '11%']
            })
            
            fig = px.bar(risk_factors, x='Impact', y='Factor', orientation='h',
                        text='Percentage', color='Impact',
                        color_continuous_scale='Reds')
            fig.update_layout(height=300, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)

elif page == "üíº Portfolio Analysis":
    st.markdown('<h1 class="main-header">üíº Portfolio Risk Analysis</h1>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("Upload Portfolio")
        
        uploaded_file = st.file_uploader("Upload CSV", type=['csv'])
        
        if uploaded_file is None:
            st.info("‚ÑπÔ∏è Using demo portfolio: 5 holdings loaded")
            portfolio_df = pd.DataFrame({
                'Company': ['Apple', 'Microsoft', 'JPMorgan', 'Ford', 'ExxonMobil'],
                'Ticker': ['AAPL', 'MSFT', 'JPM', 'F', 'XOM'],
                'Allocation': [30, 15, 25, 20, 10],
                'Current_Value': [300000, 150000, 250000, 200000, 100000]
            })
        else:
            portfolio_df = pd.read_csv(uploaded_file)
        
        scenario_choice = st.selectbox(
            "Test Against Scenario",
            ["Severe Recession", "Mild Growth", "Financial Crisis", "All 100 Scenarios (Avg)"]
        )
        
        if st.button("üîç Analyze Portfolio", type="primary"):
            st.session_state.portfolio_analyzed = True
    
    with col2:
        if st.session_state.portfolio_analyzed:
            st.subheader("üìä Portfolio Health")
            
            # Calculate portfolio risk
            risk_scores = [35, 28, 62, 78, 55]  # Demo risk scores
            portfolio_risk = sum(r * a for r, a in zip(risk_scores, portfolio_df['Allocation'])) / 100
            
            st.metric("Overall Risk Score", f"{portfolio_risk:.0f}/100", 
                     delta="Moderate Risk", delta_color="inverse")
            
            # Risk heatmap
            st.subheader("üó∫Ô∏è Risk Heatmap")
            
            heatmap_data = portfolio_df.copy()
            heatmap_data['Risk_Score'] = risk_scores
            heatmap_data['Risk_Level'] = pd.cut(heatmap_data['Risk_Score'], 
                                                bins=[0, 40, 65, 100],
                                                labels=['Low', 'Moderate', 'High'])
            
            fig = px.treemap(heatmap_data, 
                           path=['Company'], 
                           values='Allocation',
                           color='Risk_Score',
                           color_continuous_scale='RdYlGn_r',
                           hover_data=['Risk_Level', 'Allocation'])
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # Portfolio performance
            st.subheader("üéØ Expected Portfolio Performance")
            
            total_value = portfolio_df['Current_Value'].sum()
            stressed_value = total_value * 0.782  # 21.8% loss
            
            perf_cols = st.columns(3)
            with perf_cols[0]:
                st.metric("Current Value", f"${total_value:,.0f}")
            with perf_cols[1]:
                st.metric("Stressed Value", f"${stressed_value:,.0f}", 
                         delta=f"-{((1-stressed_value/total_value)*100):.1f}%",
                         delta_color="inverse")
            with perf_cols[2]:
                st.metric("Expected Loss", "-21.8%", delta_color="inverse")
            
            # Recommendations
            st.subheader("üí° Optimization Suggestions")
            st.markdown("""
            - ‚úì Reduce Ford to 10% (-50% position) - Lower cyclical exposure
            - ‚úì Increase Apple to 35% - More resilient tech allocation  
            - ‚úì Add defensive sector exposure (Healthcare/Consumer Staples)
            - ‚úì Consider diversification into bonds or alternative assets
            """)
            
            st.success("üìà **Rebalanced Portfolio Expected Loss: -15.2%** (vs -21.8% current)")

elif page == "üì° Monitoring":
    st.markdown('<h1 class="main-header">üì° System Monitoring</h1>', unsafe_allow_html=True)
    
    st.success("üü¢ **System Status: Healthy** | Last updated: 2 minutes ago")
    
    # Model performance
    st.subheader("üìä Model Performance (Last 30 Days)")
    
    perf_data = pd.DataFrame({
        'Metric': ['Prediction R¬≤', 'Mean Absolute Error (EPS)', 
                  'Anomaly Detection Precision', 'API Latency (p95)',
                  'System Uptime', 'Error Rate'],
        'Current': [0.78, '$0.42', '82%', '1.8s', '99.6%', '0.7%'],
        'Target': ['> 0.75', '< $0.50', '> 80%', '< 2.0s', '> 99.5%', '< 1.0%'],
        'Status': ['‚úì Pass', '‚úì Pass', '‚úì Pass', '‚úì Pass', '‚úì Pass', '‚úì Pass']
    })
    
    st.dataframe(perf_data, use_container_width=True, hide_index=True)
    
    # System stats
    col1, col2, col3 = st.columns(3)
    with col1:
        st.success("### System Health\nüü¢\nAll systems operational")
    with col2:
        st.warning("### Active Users\n23\nCurrently online")
    with col3:
        st.info("### Predictions Today\n487\n+12% vs yesterday")
    
    # Recent alerts
    st.subheader("‚ö° Recent Alerts")
    st.info("‚ÑπÔ∏è **2024-10-18 08:15** - Model retraining completed successfully")
    st.success("‚úÖ **2024-10-17 14:22** - Data validation passed: 0 critical issues")