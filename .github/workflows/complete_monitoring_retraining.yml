name: Model Monitoring & Auto-Retraining (VAE & Anomaly Only)

on:
  schedule:
    - cron: '0 2 * * 0'
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.10"
  GCP_BUCKET: "mlops-financial-stress-data"
  GCP_PROJECT: "ninth-iris-422916-f2"
  VAE_KS_THRESHOLD: "0.70"
  ANOMALY_ROCAUC_THRESHOLD: "0.75"
  NOTIFICATION_EMAIL: "finance.stress.analyser@gmail.com"

jobs:
  detect-drift:
    runs-on: ubuntu-latest
    outputs:
      vae_drift: ${{ steps.check.outputs.vae_drift }}
      vae_ks: ${{ steps.check.outputs.vae_ks }}
      anomaly_drift: ${{ steps.check.outputs.anomaly_drift }}
      anomaly_roc: ${{ steps.check.outputs.anomaly_roc }}
      any_drift: ${{ steps.check.outputs.any_drift }}
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      
      - uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT }}
      
      - run: sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc
      
      - run: |
          pip install --upgrade pip --no-cache-dir
          pip install --no-cache-dir tensorflow scipy numpy pandas scikit-learn joblib google-cloud-storage google-cloud-monitoring torch

      - run: |
          mkdir -p models/vae models/anomaly_detection data/features outputs/snorkel/data
          gsutil cp gs://${{ env.GCP_BUCKET }}/models/vae/deployment/best_model_deployment.pkl models/vae/vae_production.pkl || echo "‚ö†Ô∏è VAE not found"
          gsutil cp gs://${{ env.GCP_BUCKET }}/models/anomaly_detection/model.pkl models/anomaly_detection/model.pkl || echo "‚ö†Ô∏è Anomaly not found"
          gsutil cp gs://${{ env.GCP_BUCKET }}/data/features/macro_features_clean.csv data/features/macro_features_clean.csv || echo "‚ö†Ô∏è Macro not found"
          gsutil cp gs://${{ env.GCP_BUCKET }}/outputs/snorkel/data/snorkel_labeled_only.csv outputs/snorkel/data/snorkel_labeled_only.csv || echo "‚ö†Ô∏è Labeled not found"

      - id: check
        run: |
          python - <<'EOF'
          import pickle, pandas as pd, numpy as np, os, json, joblib
          from scipy import stats
          from sklearn.metrics import roc_auc_score
          from datetime import datetime
          
          print("="*80)
          print("üîç DRIFT DETECTION")
          print("="*80)
          
          drift_report = {'timestamp': datetime.now().isoformat(), 'models': {}}
          avg_ks, current_roc = 0.0, 0.0
          
          # VAE
          print("\n1Ô∏è‚É£ VAE")
          vae_drift = False
          try:
              with open('models/vae/vae_production.pkl', 'rb') as f:
                  vae_data = pickle.load(f)
              vae_model = vae_data.get('model') if isinstance(vae_data, dict) else vae_data
              if vae_model is None:
                  vae_model = vae_data.get('vae_model') or vae_data.get('best_model')
              
              train_data = pd.read_csv('data/features/macro_features_clean.csv')
              numeric_data = train_data.select_dtypes(include=[np.number])
              sample = numeric_data.sample(min(500, len(numeric_data)), random_state=42)
              
              if hasattr(vae_model, 'get_layer'):
                  encoder = vae_model.get_layer('encoder')
                  decoder = vae_model.get_layer('decoder')
                  encoded = encoder.predict(sample.values, verbose=0)
                  z_mean = encoded[0] if isinstance(encoded, list) else encoded
                  reconstructed = decoder.predict(z_mean, verbose=0)
              elif hasattr(vae_model, 'predict'):
                  reconstructed = vae_model.predict(sample.values, verbose=0)
              
              ks_stats = []
              for i, col in enumerate(sample.columns):
                  if i < reconstructed.shape[1]:
                      ks, _ = stats.ks_2samp(sample.iloc[:, i], reconstructed[:, i])
                      ks_stats.append(ks)
              
              avg_ks = np.mean(ks_stats)
              pass_rate = sum(1 for ks in ks_stats if ks >= 0.70) / len(ks_stats)
              vae_drift = avg_ks < 0.70
              
              print(f"‚úÖ VAE: KS={avg_ks:.4f}, {'‚ö†Ô∏è DRIFT' if vae_drift else '‚úÖ Healthy'}")
              drift_report['models']['vae'] = {
                  'drift_detected': bool(vae_drift),
                  'avg_ks': float(avg_ks),
                  'pass_rate': float(pass_rate)
              }
          except Exception as e:
              print(f"‚ùå VAE failed: {e}")
              drift_report['models']['vae'] = {'error': str(e)}
          
          # ANOMALY
          print("\n2Ô∏è‚É£ ANOMALY")
          anomaly_drift = False
          try:
              labeled_data = pd.read_csv('outputs/snorkel/data/snorkel_labeled_only.csv')
              split_idx = int(len(labeled_data) * 0.8)
              val_data = labeled_data.iloc[split_idx:]
              
              non_numeric_cols = ['AT_RISK', 'Date', 'Company', 'Sector', 'Year', 'Quarter', 'Ticker', 'Industry']
              feature_cols = [c for c in val_data.columns if c not in non_numeric_cols]
              numeric_features = val_data[feature_cols].select_dtypes(include=[np.number])
              X_val = numeric_features.fillna(0).values
              y_val = val_data['AT_RISK'].values
              
              with open('models/anomaly_detection/model.pkl', 'rb') as f:
                  model_data = joblib.load(f)
              anomaly_model = model_data.get('model') if isinstance(model_data, dict) else model_data
              if anomaly_model is None:
                  anomaly_model = model_data.get('anomaly_model') or model_data.get('best_model')
              
              scores = anomaly_model.score_samples(X_val) if hasattr(anomaly_model, 'score_samples') else -anomaly_model.predict(X_val)
              current_roc = roc_auc_score(y_val, -scores)
              baseline_roc = 0.85
              roc_drop_pct = ((baseline_roc - current_roc) / baseline_roc * 100) if baseline_roc > 0 else 0
              anomaly_drift = current_roc < 0.75 or roc_drop_pct > 5
              
              print(f"‚úÖ Anomaly: ROC-AUC={current_roc:.4f}, {'‚ö†Ô∏è DRIFT' if anomaly_drift else '‚úÖ Healthy'}")
              drift_report['models']['anomaly'] = {
                  'drift_detected': bool(anomaly_drift),
                  'current_roc_auc': float(current_roc),
                  'baseline_roc_auc': float(baseline_roc),
                  'roc_drop_pct': float(roc_drop_pct)
              }
          except Exception as e:
              print(f"‚ùå Anomaly failed: {e}")
              drift_report['models']['anomaly'] = {'error': str(e)}
          
          # SUMMARY
          vae_drift_bool = bool(drift_report['models'].get('vae', {}).get('drift_detected', False))
          anom_drift_bool = bool(drift_report['models'].get('anomaly', {}).get('drift_detected', False))
          any_drift = bool(vae_drift_bool or anom_drift_bool)
          
          print(f"\n{'='*80}")
          print(f"VAE: {'‚ö†Ô∏è DRIFT' if vae_drift_bool else '‚úÖ Healthy'}, Anomaly: {'‚ö†Ô∏è DRIFT' if anom_drift_bool else '‚úÖ Healthy'}")
          
          # CLOUD MONITORING
          try:
              from google.cloud import monitoring_v3
              import time
              client = monitoring_v3.MetricServiceClient()
              project_name = f"projects/{os.getenv('GCP_PROJECT')}"
              time_series = []
              now = time.time()
              
              if avg_ks > 0:
                  series = monitoring_v3.TimeSeries()
                  series.metric.type = 'custom.googleapis.com/financial_stress/vae/reconstruction_ks'
                  series.resource.type = 'global'
                  series.metric.labels['model_type'] = 'vae'
                  series.points = [monitoring_v3.Point({"interval": {"end_time": {"seconds": int(now)}}, "value": {"double_value": float(avg_ks)}})]
                  time_series.append(series)
              
              if current_roc > 0:
                  series = monitoring_v3.TimeSeries()
                  series.metric.type = 'custom.googleapis.com/financial_stress/anomaly/roc_auc'
                  series.resource.type = 'global'
                  series.metric.labels['model_type'] = 'anomaly'
                  series.points = [monitoring_v3.Point({"interval": {"end_time": {"seconds": int(now)}}, "value": {"double_value": float(current_roc)}})]
                  time_series.append(series)
              
              if time_series:
                  client.create_time_series(name=project_name, time_series=time_series)
                  print("‚úÖ Logged to Cloud Monitoring")
          except Exception as e:
              print(f"‚ö†Ô∏è Cloud Monitoring failed: {e}")
          
          # SAVE REPORT
          drift_report['any_drift'] = any_drift
          os.makedirs('reports', exist_ok=True)
          with open('reports/drift_report.json', 'w') as f:
              json.dump(drift_report, f, indent=2)
          
          import subprocess
          timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
          subprocess.run(['gsutil', 'cp', 'reports/drift_report.json', f'gs://mlops-financial-stress-data/monitoring/drift_reports/drift_{timestamp}.json'], capture_output=True)
          
          # OUTPUTS
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"vae_drift={str(vae_drift_bool).lower()}\n")
              f.write(f"vae_ks={avg_ks:.4f}\n")
              f.write(f"anomaly_drift={str(anom_drift_bool).lower()}\n")
              f.write(f"anomaly_roc={current_roc:.4f}\n")
              f.write(f"any_drift={str(any_drift).lower()}\n")
          
          print("‚úÖ COMPLETE")
          EOF

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: drift-report
          path: reports/drift_report.json
          retention-days: 30

      - uses: dawidd6/action-send-mail@v3
        if: steps.check.outputs.any_drift == 'true'
        continue-on-error: true
        with:
          server_address: smtp.gmail.com
          server_port: 587
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: "üö® Drift Detected - Retraining Started"
          to: ${{ env.NOTIFICATION_EMAIL }}
          from: ${{ secrets.EMAIL_USERNAME }}
          body: |
            üö® DRIFT DETECTED
            
            VAE: ${{ steps.check.outputs.vae_drift == 'true' && '‚ö†Ô∏è DRIFT' || '‚úÖ OK' }} (KS: ${{ steps.check.outputs.vae_ks }})
            Anomaly: ${{ steps.check.outputs.anomaly_drift == 'true' && '‚ö†Ô∏è DRIFT' || '‚úÖ OK' }} (ROC: ${{ steps.check.outputs.anomaly_roc }})
            
            Retraining started. Check: https://github.com/Novia-Dsilva/Mlops_Project_FinancialCrises/actions

  retrain-vae:
    runs-on: ubuntu-latest
    needs: [detect-drift]
    if: needs.detect-drift.outputs.vae_drift == 'true'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      - uses: google-github-actions/setup-gcloud@v2
      - run: sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc
      - run: pip install -r requirements.txt mlflow
      - run: |
          mkdir -p data/features
          gsutil cp gs://${{ env.GCP_BUCKET }}/data/features/macro_features_clean.csv data/features/
      - run: |
          python src/models/vae/Dense_VAE_optimized_mlflow_updated.py || echo "Dense VAE done"
          python src/models/vae/Ensemble_VAE_updated.py || echo "Ensemble VAE done"
        continue-on-error: true
      - id: validate
        run: |
          python - <<'EOF'
          import json, glob, os
          metrics_files = glob.glob('models/vae/*_metrics.json')
          if not metrics_files:
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write("deploy=false\n")
              exit(0)
          best_ks, best_model = 0.0, None
          for mf in metrics_files:
              with open(mf) as f:
                  m = json.load(f)
              ks = m.get('avg_ks_statistic', 0.0)
              name = os.path.basename(mf).replace('_metrics.json', '')
              if ks > best_ks:
                  best_ks, best_model = ks, name
          passes = best_ks >= 0.70
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"best_model={best_model}\n")
              f.write(f"best_ks={best_ks:.4f}\n")
              f.write(f"deploy={str(passes).lower()}\n")
          print(f"Best: {best_model} (KS={best_ks:.4f}) - {'‚úÖ DEPLOY' if passes else '‚ùå SKIP'}")
          EOF
      - if: steps.validate.outputs.deploy == 'true'
        run: |
          timestamp=$(date +%Y%m%d_%H%M%S)
          gsutil cp gs://${{ env.GCP_BUCKET }}/models/vae/deployment/best_model_deployment.pkl \
                     gs://${{ env.GCP_BUCKET }}/models/vae/deployment/backups/backup_${timestamp}.pkl || echo "No backup"
          gsutil cp models/vae/${{ steps.validate.outputs.best_model }}.pkl \
                     gs://${{ env.GCP_BUCKET }}/models/vae/deployment/best_model_deployment.pkl
          echo "‚úÖ Deployed: ${{ steps.validate.outputs.best_model }} (KS=${{ steps.validate.outputs.best_ks }})"

  retrain-anomaly:
    runs-on: ubuntu-latest
    needs: [detect-drift]
    if: needs.detect-drift.outputs.anomaly_drift == 'true'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      - uses: google-github-actions/setup-gcloud@v2
      - run: sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc
      - run: pip install -r requirements.txt mlflow
      - run: |
          mkdir -p outputs/snorkel/data
          gsutil cp gs://${{ env.GCP_BUCKET }}/outputs/snorkel/data/snorkel_labeled_only.csv outputs/snorkel/data/
      - run: python src/models/train_anomaly_detection.py
        continue-on-error: true
      - id: validate
        run: |
          python - <<'EOF'
          import json, glob, os
          metrics_files = glob.glob('outputs/models/results/*_metrics.json')
          if not metrics_files:
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write("deploy=false\n")
              exit(0)
          best_roc = max(json.load(open(mf)).get('roc_auc', 0.0) for mf in metrics_files)
          passes = best_roc >= 0.75
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"best_roc={best_roc:.4f}\n")
              f.write(f"deploy={str(passes).lower()}\n")
          print(f"Best ROC-AUC={best_roc:.4f} - {'‚úÖ DEPLOY' if passes else '‚ùå SKIP'}")
          EOF
      - if: steps.validate.outputs.deploy == 'true'
        run: |
          timestamp=$(date +%Y%m%d_%H%M%S)
          gsutil cp gs://${{ env.GCP_BUCKET }}/models/anomaly_detection/model.pkl \
                     gs://${{ env.GCP_BUCKET }}/models/anomaly_detection/backups/backup_${timestamp}.pkl || echo "No backup"
          gsutil cp models/anomaly_detection/model.pkl gs://${{ env.GCP_BUCKET }}/models/anomaly_detection/
          echo "‚úÖ Deployed new anomaly model (ROC-AUC=${{ steps.validate.outputs.best_roc }})"

  notify-complete:
    runs-on: ubuntu-latest
    needs: [detect-drift, retrain-vae, retrain-anomaly]
    if: always()
    steps:
      - uses: dawidd6/action-send-mail@v3
        continue-on-error: true
        with:
          server_address: smtp.gmail.com
          server_port: 587
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: "üìä Monitoring Complete"
          to: ${{ env.NOTIFICATION_EMAIL }}
          from: ${{ secrets.EMAIL_USERNAME }}
          body: |
            üìä MONITORING COMPLETE
            
            VAE: ${{ needs.detect-drift.outputs.vae_drift == 'true' && '‚ö†Ô∏è Retrained' || '‚úÖ Healthy' }}
            Anomaly: ${{ needs.detect-drift.outputs.anomaly_drift == 'true' && '‚ö†Ô∏è Retrained' || '‚úÖ Healthy' }}
            
            Details: https://github.com/Novia-Dsilva/Mlops_Project_FinancialCrises/actions

  summary:
    runs-on: ubuntu-latest
    needs: [detect-drift, retrain-vae, retrain-anomaly]
    if: always()
    steps:
      - run: |
          echo "=========================================="
          echo "DRIFT MONITORING SUMMARY"
          echo "=========================================="
          echo "VAE:     ${{ needs.detect-drift.outputs.vae_drift }} (KS: ${{ needs.detect-drift.outputs.vae_ks }})"
          echo "Anomaly: ${{ needs.detect-drift.outputs.anomaly_drift }} (ROC: ${{ needs.detect-drift.outputs.anomaly_roc }})"
          echo "=========================================="