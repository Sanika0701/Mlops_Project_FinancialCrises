name: Model Monitoring & Auto-Retraining (VAE & Anomaly Only)

on:
  schedule:
    - cron: '0 2 * * 0'
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.10"
  GCP_BUCKET: "mlops-financial-stress-data"
  GCP_PROJECT: "ninth-iris-422916-f2"
  VAE_KS_THRESHOLD: "0.70"
  ANOMALY_ROCAUC_THRESHOLD: "0.75"
  NOTIFICATION_EMAIL: "finance.stress.analyser@gmail.com"

jobs:
  detect-drift:
    runs-on: ubuntu-latest
    outputs:
      vae_drift: ${{ steps.check.outputs.vae_drift }}
      vae_ks: ${{ steps.check.outputs.vae_ks }}
      anomaly_drift: ${{ steps.check.outputs.anomaly_drift }}
      anomaly_roc: ${{ steps.check.outputs.anomaly_roc }}
      any_drift: ${{ steps.check.outputs.any_drift }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT }}
      
      - name: Free disk space
        run: sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip --no-cache-dir
          pip install --no-cache-dir tensorflow scipy numpy pandas scikit-learn joblib google-cloud-storage google-cloud-monitoring torch

      - name: Download production models and reference data
        run: |
          echo "üì• Downloading production models..."
          mkdir -p models/vae models/anomaly_detection data/features outputs/snorkel/data
          
          gsutil cp gs://${{ env.GCP_BUCKET }}/models/vae/deployment/best_model_deployment.pkl \
                    models/vae/vae_production.pkl || echo "‚ö†Ô∏è VAE not found"
          
          gsutil cp gs://${{ env.GCP_BUCKET }}/models/anomaly_detection/model.pkl \
                    models/anomaly_detection/model.pkl || echo "‚ö†Ô∏è Anomaly not found"
          
          gsutil cp gs://${{ env.GCP_BUCKET }}/data/features/macro_features_clean.csv \
                    data/features/macro_features_clean.csv || echo "‚ö†Ô∏è Macro features not found"
          
          gsutil cp gs://${{ env.GCP_BUCKET }}/outputs/snorkel/data/snorkel_labeled_only.csv \
                    outputs/snorkel/data/snorkel_labeled_only.csv || echo "‚ö†Ô∏è Labeled data not found"
          
          echo "‚úÖ Download complete"

      - name: Drift Detection
        id: check
        run: |
          python - <<'EOF'
          import pickle, pandas as pd, numpy as np, os, json, joblib
          from scipy import stats
          from sklearn.metrics import roc_auc_score
          from datetime import datetime
          
          print("="*80)
          print("üîç DRIFT DETECTION - VAE & ANOMALY")
          print("="*80)
          
          drift_report = {'timestamp': datetime.now().isoformat(), 'models': {}}
          avg_ks, current_roc = 0.0, 0.0
          
          # VAE DRIFT
          print("\n1Ô∏è‚É£ VAE MODEL")
          vae_drift = False
          try:
              with open('models/vae/vae_production.pkl', 'rb') as f:
                  vae_data = pickle.load(f)
              vae_model = vae_data.get('model') if isinstance(vae_data, dict) else vae_data
              if vae_model is None:
                  vae_model = vae_data.get('vae_model') or vae_data.get('best_model')
              
              train_data = pd.read_csv('data/features/macro_features_clean.csv')
              numeric_data = train_data.select_dtypes(include=[np.number])
              sample = numeric_data.sample(min(500, len(numeric_data)), random_state=42)
              
              if hasattr(vae_model, 'get_layer'):
                  encoder = vae_model.get_layer('encoder')
                  decoder = vae_model.get_layer('decoder')
                  encoded = encoder.predict(sample.values, verbose=0)
                  z_mean = encoded[0] if isinstance(encoded, list) else encoded
                  reconstructed = decoder.predict(z_mean, verbose=0)
              elif hasattr(vae_model, 'predict'):
                  reconstructed = vae_model.predict(sample.values, verbose=0)
              
              ks_stats = []
              for i, col in enumerate(sample.columns):
                  if i < reconstructed.shape[1]:
                      ks, _ = stats.ks_2samp(sample.iloc[:, i], reconstructed[:, i])
                      ks_stats.append(ks)
              
              avg_ks = np.mean(ks_stats)
              pass_rate = sum(1 for ks in ks_stats if ks >= 0.70) / len(ks_stats)
              vae_drift = avg_ks < 0.70
              
              print(f"‚úÖ VAE: KS={avg_ks:.4f}, Status={'‚ö†Ô∏è DRIFT' if vae_drift else '‚úÖ Healthy'}")
              drift_report['models']['vae'] = {
                  'drift_detected': bool(vae_drift),
                  'avg_ks': float(avg_ks),
                  'pass_rate': float(pass_rate)
              }
          except Exception as e:
              print(f"‚ùå VAE failed: {e}")
              drift_report['models']['vae'] = {'error': str(e)}
          
          # ANOMALY DRIFT
          print("\n2Ô∏è‚É£ ANOMALY MODEL")
          anomaly_drift = False
          try:
              labeled_data = pd.read_csv('outputs/snorkel/data/snorkel_labeled_only.csv')
              split_idx = int(len(labeled_data) * 0.8)
              val_data = labeled_data.iloc[split_idx:]
              
              non_numeric_cols = ['AT_RISK', 'Date', 'Company', 'Sector', 'Year', 'Quarter', 'Ticker', 'Industry']
              feature_cols = [c for c in val_data.columns if c not in non_numeric_cols]
              numeric_features = val_data[feature_cols].select_dtypes(include=[np.number])
              X_val = numeric_features.fillna(0).values
              y_val = val_data['AT_RISK'].values
              
              with open('models/anomaly_detection/model.pkl', 'rb') as f:
                  model_data = joblib.load(f)
              anomaly_model = model_data.get('model') if isinstance(model_data, dict) else model_data
              if anomaly_model is None:
                  anomaly_model = model_data.get('anomaly_model') or model_data.get('best_model')
              
              scores = anomaly_model.score_samples(X_val) if hasattr(anomaly_model, 'score_samples') else -anomaly_model.predict(X_val)
              current_roc = roc_auc_score(y_val, -scores)
              baseline_roc = 0.85
              roc_drop_pct = ((baseline_roc - current_roc) / baseline_roc * 100) if baseline_roc > 0 else 0
              anomaly_drift = current_roc < 0.75 or roc_drop_pct > 5
              
              print(f"‚úÖ Anomaly: ROC-AUC={current_roc:.4f}, Status={'‚ö†Ô∏è DRIFT' if anomaly_drift else '‚úÖ Healthy'}")
              drift_report['models']['anomaly'] = {
                  'drift_detected': bool(anomaly_drift),
                  'current_roc_auc': float(current_roc),
                  'baseline_roc_auc': float(baseline_roc),
                  'roc_drop_pct': float(roc_drop_pct)
              }
          except Exception as e:
              print(f"‚ùå Anomaly failed: {e}")
              drift_report['models']['anomaly'] = {'error': str(e)}
          
          # SUMMARY
          vae_drift_bool = bool(drift_report['models'].get('vae', {}).get('drift_detected', False))
          anom_drift_bool = bool(drift_report['models'].get('anomaly', {}).get('drift_detected', False))
          any_drift = bool(vae_drift_bool or anom_drift_bool)
          
          print(f"\n{'='*80}")
          print(f"VAE: {'‚ö†Ô∏è DRIFT' if vae_drift_bool else '‚úÖ Healthy'}, Anomaly: {'‚ö†Ô∏è DRIFT' if anom_drift_bool else '‚úÖ Healthy'}")
          
          # SAVE REPORT
          drift_report['any_drift'] = any_drift
          os.makedirs('reports', exist_ok=True)
          with open('reports/drift_report.json', 'w') as f:
              json.dump(drift_report, f, indent=2)
          
          # OUTPUTS
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"vae_drift={str(vae_drift_bool).lower()}\n")
              f.write(f"vae_ks={avg_ks:.4f}\n")
              f.write(f"anomaly_drift={str(anom_drift_bool).lower()}\n")
              f.write(f"anomaly_roc={current_roc:.4f}\n")
              f.write(f"any_drift={str(any_drift).lower()}\n")
          
          print("‚úÖ COMPLETE")
          EOF

      - name: Upload drift report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: drift-report
          path: reports/drift_report.json
          retention-days: 30

  summary:
    runs-on: ubuntu-latest
    needs: [detect-drift]
    if: always()
    steps:
      - name: Display Summary
        run: |
          echo "=========================================="
          echo "  DRIFT MONITORING SUMMARY"
          echo "=========================================="
          echo "VAE:     ${{ needs.detect-drift.outputs.vae_drift }} (KS: ${{ needs.detect-drift.outputs.vae_ks }})"
          echo "Anomaly: ${{ needs.detect-drift.outputs.anomaly_drift }} (ROC: ${{ needs.detect-drift.outputs.anomaly_roc }})"
          echo "=========================================="